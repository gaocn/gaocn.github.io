---
layout:     post
title:      "统计学基础"
subtitle:   
date:       2018-01-14
author:     "Govind"
header-img: "img/post_bg/19.jpg"
tags:
    - 统计学
---



## 统计学基础

统计学可以分为：描述统计学与推断统计学

**描述统计学**：使用特定的数字或图表来体现数据的集中程度和离散程度。例：每次考试算的平均分，最高分，各个分段的人数分布等，也是属于描述统计学的范围。在大数据时代，数据量是非常大的，没有办法一一查看数据中的详细信息，因此通过描述统计学帮助我们对整体有一个认识。

**推断统计学**：根据样本数据推断总体数据特征。例：产品质量检查，一般采用抽检，根据所抽样本的质量合格率作为总体的质量合格率的一个估计。很多时候，我们队整体不是很了解，需要通过样本去认识整体。

### 描述统计学--数据特征描述分析

**集中趋势** 

例：对于1 2 3 4 5这组数据，你会使用哪个数字作为代表？对于一组数据，如果只容许使用一个数字去代表这组数据，那么这个数字应该如何选
择？？——`选择数据的中心，即反映数据集中趋势的统计量 `。

常用的描述数据集中趋势的尺度：

- 均值——算术平均数，描述`平均水平`；均值为$u = \frac{1}{N}\sum_{i=1}^{N}X_i = \frac{1}{N}(X_1 + X_2 + ... + Xn)$ ，例：某次数学考试中，小组A与小组B的成员的成绩分别如下：A：70,85,62,98,92 B：82,87,95,80,83分别求出两组的平均分，并比较两组的成绩。组A：（70+85+62+98+92）/5=81.4，组B：（82+87+95+80+83）/5=85.4，组B的平均分比组A的高，就是组B的总体成绩比组A高。
- 中位数——将数据按大小排列后位于正中间的数，描述`中等水平`；例如：可以查看中产阶级的收入情况。例： 58,32,46,92,73,88,23，求中位数，先排序：23,32,46,`58`,73,88,92，找出处于中间位置的数：23,32,46,`58`,73,88,92。三个数字比58小，三个数字比58大。58,32,46,92,73,88,23,63——多加了一个数字，情况有何改变？先排序：23,32,46,58,63,73,88,92，找出处于中间位置的数：23,32,46,`58,63`,73,88,92，若处于中间位置的数据有两个（也就是数据的总个数为偶数时），中位数为中间两个数的算术平均数：（58+63）/2=60.5——原数据中，四个数字比60.5小，四个数字比60.5大
- 众数——数据中出现最多的数，描述`一般水平`；一组数据中，可能会存在多个众数，也可能不存在众数。1 2 2 3 3 中的众数是2和3，1 2 3 4 5 中没有众数。众数不仅适用于数值型数据，对于非数值型数据也同样适用。{苹果，苹果，香蕉，橙，橙，橙，桃}这一组数据，没有什么均值中位数可言，但是存在着众数——橙

|      | 优点                        | 缺点                        |
| ---- | ------------------------- | ------------------------- |
| 均值   | 充分利用所有数据，适用性强             | 容易受到极端值的影响                |
| 中位数  | 不受极端值影响                   | 缺乏敏感性                     |
| 众数   | 当数据具有明显集中趋势时，代表性好，不受极端值影响 | 缺乏唯一性：可能有一个，可能有两个，可能一个都没有 |

![和众数、中位数、均值](/img/md_imgs/和众数、中位数、均值.png)

从上图可以知道，对于有偏数据，中位数、均值和众数的大小是不同的。

正倾斜数据（众数<中位数<均值）：小的数据比较多，大的数据比较少。就像社会上的收入一样，这时候众数是比较小的，即一般不普通大众的收入情况，而中位数则可以反应中产家庭的收入，均值就是整体社会的收入水平。不同城市之间平均收入对比一般采用均值进行比较，而没有考虑低收入家庭的情况。

负倾斜数据（众均值<中位数<数）：小的数据比较少，大的数据比较多。

**范例**：两个公司的员工及薪资构成如下：A：经理1名，月薪100000；高级员工，15名，月薪10000；普通员工20名，月薪7500；B：经理1名，月薪20000；高级员工，20名，月薪11000；普通员工15名，月薪9000。 请比较两家公司的薪资水平。若只考虑薪资，你会选择哪一家公司？

- 均值：A （100000+15*10000+20*7500）/36=11111.1，B （20000+20*11000+15*9000）/36=10416.67。
- 中位数：A 7500 B 11000
- 众数：A 7500 B 11000

若从均值去考虑，明显地A公司的平均月薪比B公司的高，但是A公司存在一个极端值（极端值对均值影响较大），大大地拉高了A公司的均值，这时只从均值考虑明显不太科学。从中位数和众数来看，B公司的薪资水平比较高，若是一般的员工，选择B公司显得更加合理。

**离散趋势** （极差、方差、标准差）

仅仅对数据进行集中趋势的描述不能够对数据进行充分的了解，例如：比较下面两组数据：A=(1 2 5 8 9)， B=(3 4 5 6 7)，两组数据的均值都是5，但是可以看出B组的数据与5更加接近。因此仅仅有描述集中趋势的统计量不够，需要有描述数据的离散程度的统计量。

![离散趋势](/img/md_imgs/离散趋势.png)

==极差==：最大值-最小值，简单地描述数据的范围大小 。同样的5个数，A的极差比B的极差要大，所以也比B的要分散。但是只用极差这个衡量离散程度也存在不足，如：A=(1 2 5 8 9)， B=(1 4 5 6 9)。



==方差== ：在统计学上，更常地是使用方差$\delta^2 = \frac{1}{N}\sum_{i=1}{N}(X_i - \mu)$来描述数据的离散程度（`数据离中心越远越离散`），其中，$X_i$表示数据集中第i个数据的值，表示数据集的均值。`注意：大部分情况下，我们都是计算样本方差，因此会除以（N-1）而不是N，大部分计算软件中的方差也都是除以（N-1）。`

例如：A=(1 2 5 8 9)， B=(3 4 5 6 7)，则有：

$\delta^2_A=\frac{1}{5}[(1-5)^2 + (2-5)^2 + (5-5)^2 + (8-5)^2+(9-5)^2] = 10$

$\delta^2_B=\frac{1}{5}[(3-5)^2 + (4-5)^2 + (5-5)^2 + (6-5)^2+(7-5)^2] = 2$

`方差的简化运算` 

$\delta^2 =  \frac{1}{N}\sum_{i=1}{N}(X_i - \mu) = \frac{1}{N}\sum_{i=1}{N}[(X_1-\mu)^2 + (X_2 - \mu)^2 + ... + (X_n - \mu)^2] \\ =\frac{1}{N}[(X_1^2 - 2X_{1}\mu + \mu^2) + X_2^2 - 2X_{2}\mu + \mu^2) + ... + X_N^2 - 2X_{N}\mu + \mu^2) ] \\ =\frac{1}{N}[X_1^2 + X_2^2 + ... + X_N^2 + 2\mu(X_1+X_2+...+X_N) + N\mu^2] \\ =\frac{1}{N}[X_1^2 + X_2^2 + ... + X_N^2] -2\mu*\frac{1}{N}(X_1+X_2+...+X_N) + \mu^2 \\ =\frac{1}{N}\sum_{i=1}^{N}X_{i}^2 - 2\mu^2 + \mu^2 \\ =\frac{1}{N}\sum_{i=1}^{N}X_{i}^2 - \mu^2$

==标准差==  对于数据1 2 5 8 9 ，前面求得这一组数据的方差是10。将10与原数据作比较，可以看出10比原数据都大，是否说明这一组数据十分离散呢？？但是方差与原数据的单位是不一样的，这样的比较是无意义的。如果原数据的单位是m的话，那么方差的单位就是m^2。 为了保持单位的一致性，我们引入一个新的统计量——标准差。标准差$\delta=\sqrt{\delta^2}$，`有效地避免了因单位平方而引起的度量问题` ，标准差的意义和方差是一样的，数据越大表示数据的离散程度越大。

**范例**： 一次数学考试中，A班同学的成绩如下：98 83 65 72 79 76 75 94 91 77 63 83 89 69 64 78 63 86 91 72 71 72 70 80 65 70 62 74 71 76，（1）求A班的平均分，以及成绩的中位数与众数；（2）若小明的成绩是86，则小明的数学成绩怎么样？中上游水平（3）求A班成绩的标准差。

**偏度** 

对数据分布的偏斜程度的衡量，分为正偏和负偏。偏度$skew = E[\frac{X-\mu}{\delta}]^3$ ，E是期望值即平均值。在pandas中使用函数skew计算数据的偏度。

**峰度（kurtosis）**

对数据分布峰态的度量指标，分为：尖峰、中峰、低峰、超额峰度。$kurt = E[\frac{X-\mu}{\delta}]^4$ 。峰度越大表示越陡峭，越难爬，而峰度越小表示越平缓。正态分布的峰度为3，因此计算时通常会将峰度减3得到超额峰度，在pandas中使用函数kurt计算超额峰度，若大于零，表示比正太分布要陡峭，若是超额峰度小于零，表示数据分布比正太分布平缓。

**分位数** 

将数据 Xi 按从小到大的顺序分为两组，较小的一组的元素个数占整个样本元素个数的α，分组的临界值为α分位数Xa，即P{X<Xa} = F(Xa) =a 

```python
#In [14]: s.describe()
#Out[14]:
#count    30.000000  数据量
#mean     75.966667  均值
#std       9.824260  方差
#min      62.000000  最小值
#25%      70.000000  25%分位数（上四分位数）
#50%      74.500000  中位数
#75%      82.250000  75%分位数（下四分位数）
#max      98.000000  最大值
```

**不同组数据间的数据特征、关系（方差、协方差、相关系数）**


$$
S_{xx} = \frac{1}{N-1}\sum_{i=1}{n}(x_i-\overline{x})^2 \\
S_{yy} = \frac{1}{N-1}\sum_{i=1}{n}(y_i-\overline{y})^2 \\
S_{xy} = \frac{1}{N-1}\sum_{i=1}{n}(x_i-\overline{x})(y_i-\overline{y}) \\
则称S_{xx}为变量X的观测样本的方差，S_{yy}为变量Y的观测样本方差，X_{xy}为变量X,Y的观测样本协方差，称 \\
S = \lgroup\begin{matrix}
S_{xx} & S_{xy} \\
S_{xy}&S_{yy}
\end{matrix} \rgroup \\
为观测样本的协方差，称r= \frac{S_{xx}}{\sqrt{S_{xx}}\sqrt{S_{yy}}}为莞城样本的的相关系数。
$$

```python
df = DataFrame({'data1':np.random.randn(5), 'data2':np.random.randn(5)})
#      data1     data2
#0 -0.580076 -0.252774
#1 -1.281471 -0.349136
#2 -1.820013 -0.857301
#3  1.814818 -1.470563
#4 -0.299968  1.642440

df.cov()
#          data1     data2
#data1  1.933931 -0.391251
#data2 -0.391251  1.362369

 df.corr()
#          data1     data2
#data1  1.000000 -0.241039
#data2 -0.241039  1.000000
```

### 推断统计学（假设检验）

假设检验(Hypothesis Testing)是数理统计学中根据一定假设条件由样本推断总体的一种方法

假设检验的基本思想是小概率反证法思想。小概率思想是指小概率事件（P<0.01或P<0.05）在一次试验中基本上不会发生。反证法思想是先提出假设(检验假设H0)，再用适当的统计方法确定假设成立的可能性大小，如可能性小，则认为假设不成立，若可能性大，则还不能认为假设成立（不 拒绝零假设，但不会说接受，因为这次没法推翻，还有下次）。目标是：想办法推翻零假设。

假设检验的基本步骤

1. 提出零假设；
2. 建立检验统计量；
3. 确定否定域/计算P值；
4. 得出结论；

>null hypothesis is a statement that the value of a population parameter is equal to some claimed value 

零假设是假定一个总体参数等于某个特定值的一个声明，用H0表示。如$H0:  = 0.5；H0: μ = 98.6；H0: σ = 15$

备择假设是假定该总体参数为零假设中假设的值除外的值，用H1表示。如$H1：p  \gt 0.5； H1: p \lt 0.5；H1: p \ne 0.5$

**零假设与备择假设的选择**：若希望假设的论断成立，设为备择假设；若希望假设的论断不成立，设为零假设。

零假设与备选假设，零假设是需要想办法推翻的，从而证明备择假设是正确的。类似无罪推定原理，首先法庭会假设无罪的（零假设），然后警察需要找足够的证据证明假设是错误的。但是会存在这样一种情况，警察找不到证据，即我们没有办法推翻零假设，或者我们选择的样本数据刚好会证明零假设是正确的。这时候，我们不拒绝零假设，但是不会接受零假设，可能会在以后的证据搜索过程中拒绝零假设。

例：可口可乐公司声称：每罐可乐的平均重量最小为12安士。若可口可乐公司想要证明他们声称的是正确的，那么零假设：平均重量为12安士；备择假设为：平均重量是大于12安士的。若要证明可口可乐公司是错误的，零假设为：平均重量为12安士，备择假设：平均重量小于12安士。

若要证明下面假设是正确的，分别写出它们的零假设与备择假设：

1. 通过网站找到工作的求职者比例超过0.5；零假设：找到工作的求职者比例为0.5；备择假设：找到工作的求职者比例超过0.5。
2. 飞机乘客的平均重量（包括乘客的手提行李）最多为195磅；零假设：平均重量为195；备择假设：平均重量小于195。
3. 演员的IQ成绩的标准差为15；零假设：IQ标准差为15；备择假设：IQ标准差不等于15。

**检验统计量** 

>The test statistic is a value used in making a decision about the null hypothesis , and it is found by converting the sample statistic to a score with the assumption that the null hypothesis is true. 

检验统计量是一个用于确定零假设是否为真的一个值，这个值在假定零假设为真时由样本数据计算得到的。通常会把检验统计量转换为我们比较熟悉的分布，例如：正太分布，t分布，f分布，卡方分布等，对别对应于f检验，f检验，卡法检验。

**否定域、拒绝域** 

拒绝域，也称否定域，是指检验统计量所有可以拒绝零假设的取值所构成的集合。

`显著性水平α`，指当零假设正确的时候，检验统计量落在拒绝域的概率。也就是当零假设为真而我们却拒绝零假设这种错误发生的概率。与置信区间中的显著性水平α意义一致。常用取值：0.1,0.05,0.01

`临界值` ：拒绝域与非拒绝域的分界线 

`P-value`：样本发生或者比样本更极端的情况发生的概率。例如：灯泡的平均寿命是3000，而获取到的样本的平均寿命为2900，那么2900是比3000低的，那么这个低的程度是不是在可接受的范围呢？就需要计算样本寿命小于2900的概率，这个概率值就为P值。 P值即概率，反映某一事件发生的可能性大小。统计学根据显著性检验方法所得到的P 值，一般以P < 0.05 为有统计学差异， P<0.01 为有显著统计学差异，P<0.001为有极其显著的统计学差异。其含义是样本间的差异由抽样误差所致的概率小于0.05 、0.01、0.001。实际上，P值不能赋予数据任何重要性，只能说明某事件发生的几率。

当P<a时，则说明这是一个小概率事件，可以拒绝零假设。

**决策规则** 

| 方法       | 拒绝零假设                          | 不拒绝零假设           |
| -------- | ------------------------------ | ---------------- |
| 临界值法     | 检验统计量落在拒绝域                     | 检验统计量没有落在拒绝域     |
| P-Value法 | P值 <= a                        | P值  > a（不是小概率事件） |
| 另一个选择    | 不采用具体的a值，写出P值留给读者自己判断什么是小概率事件。 |                  |

对于假设检验通常会范两类错误：第一类错误，第二类错误。

`第一类错误` ：零假设正确的情况下拒绝了零假设，犯错概率：α --显著性水平

`第二类错误` ：零假设错误的情况下没有拒绝零假设，犯错概率：β 

当样本量不变的情况下，增大α会降低β，增大β会降低α。因此α的选择不能太低，太低很容易发生第二类错误。降低整体假设检验错误发生的概率唯一的方法就是增加样本量，这就是为什么抽样时尽量多一些数据，这样会降低第一类和第二类错误出现的概率。 

|        | 零假设为真   | 零假设为假   |
| ------ | ------- | ------- |
| 拒绝零假设  | 第一类错误，α | 正确决定    |
| 不拒绝零假设 | 正确决定    | 第二类错误，β |

**检验统计量（test statistics ）** 

- z检验，符合标准正太分布；
- t检验，服从t分布；
- 卡方检验，服从卡方分布；
- F检验，服从F分布；



**范例：样本均值检验**

我们仍然沿用上面的例子：一件物品的重量，将其称了10 次，得到的重量为10.1, 10,9.8,10.5, 9.7, 10.1, 9.9, 10.2, 10.3, 9.9, 假设所称出的物体重量服从正态分布，我们现在想知道该物品的重量是否显著不为10？

```python
from scipy import stats as ss
#
#零假设：该物品的重量是否显著为10；
#备择假设：该物品的重量是否显著不为10；
#
df = DataFrame({'data':[10.1, 10,9.8,10.5, 9.7, 10.1, 9.9, 10.2, 10.3, 9.9]})
#popmean:假设中的值
ss.ttest_1samp(a=df, popmean=10)
Ttest_1sampResult(statistic=array([ 0.65465367]), pvalue=array([ 0.52906417]))
#第一个值是检验统计量比popmean多出来的部分
#因为P值为0.53不是小概率事件，因此不能拒绝零假设
```